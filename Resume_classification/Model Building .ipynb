{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c6b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dcb9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a44a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>Anubhav Kumar Singh\\t\\t  To work in a global...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>\\tProfile Summary:\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t7+ years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>PeopleSoft Database Administrator             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>MuraliExperience Summary I have 6 years of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>Priyanka Ramadoss61/46, MountPleasant, Coonoor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               field                                             Resume\n",
       "0  Peoplesoft Resume    Anubhav Kumar Singh\\t\\t  To work in a global...\n",
       "1  Peoplesoft Resume  \\tProfile Summary:\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t7+ years...\n",
       "2  Peoplesoft Resume  PeopleSoft Database Administrator             ...\n",
       "3  Peoplesoft Resume  MuraliExperience Summary I have 6 years of exp...\n",
       "4  Peoplesoft Resume  Priyanka Ramadoss61/46, MountPleasant, Coonoor..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8156bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'field' : 'Category'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de67a741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Peoplesoft Resume'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56883423",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanresume(text):\n",
    "    text = re.sub('http\\S+\\s',' ',text) #removing urls\n",
    "    text = re.sub('#\\S+','',text)    #removing hasgtags\n",
    "    text = re.sub('@\\S+','  ',text)   #Removing '@' from text\n",
    "    text = re.sub(\"[0-9\" \"]+\",\" \",text) #removing numbers\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#S%&'()*+,-./:\n",
    "    ;<=>?@[\\]^_`{|}~\"\"\"), ' ',text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]|_|-',' ',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13be76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Anubhav Kumar ingh To work in a globally comp...\n",
      "1      Profile ummary years of experience in impleme...\n",
      "2     People oft Database Administrator Gangareddy P...\n",
      "3     MuraliExperience ummary I have years of experi...\n",
      "4     Priyanka Ramadoss MountPleasant CoonoorThe Nil...\n",
      "                            ...                        \n",
      "74     Workday Integration ConsultantName ri Krishna...\n",
      "75     eeking suitable positions in Workday HCM as T...\n",
      "76    WORKDAY HCM FCMName Kumar Role Workday Consult...\n",
      "77    Venkateswarlu B Workday Consultant Having year...\n",
      "78     Vinay kumar v Workday Functional ConsultantEX...\n",
      "Name: cleaned_resume, Length: 79, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_resume'] = df.Resume.apply(lambda x : cleanresume(x))\n",
    "print(df['cleaned_resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bdb480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Profile ummary years of experience in implementing upgrading and supporting People oft database administration including Human Capital Management HCM Financials Campus olutions and Portal IHUBExpertise in installation configuration setup security and management of the People oft Internet Architecture PIA environment In depth experience in analysis planning development and implementation stages including load testing quality assurance and tuning Gained extensive exposure in deploying People oft Environments Experienced in Troubleshooting People oft Components killed with the capability to analyse interpret unique problems with a combination of training experience logical thinking to find the right solutionsCore Competencies People oft Implementation Troubleshooting People oft performance issues Project Data Migration Installation Configuration of People oft components PUM DPK Install and configure Upgrades People tools Expertise in applying Patches and Updates via Change Assistant tool including Tax Updates Elastic earch Install and configure People oft Refreshes Cloning Integration Broker setup and configurationMaintaining workflow of People oft users monitoring log files and search bottleneck of servers People oft ecurity resetting passwords and locking unlocking user profiles Installing Middle tier components and Oracle quarterly ecurity patches Configuring Change Assistant to apply fixes and patch sets People oft Cloud Infrastructure Iaa AW EC Cloud Manager Lift and hift of application to cloud Work Experience Organization IDC Technologies ol I Pvt Ltd PROJECT Multiple clients Texas Department of Transportation TxDOT DURATION Aug to till the dateROLE People oft DBAENVIRONMENT People Tools HRM F CM Tuxedo WebLogic and Oracle c RE PON IBILITIE Performing Project Migration using Phire Performing Oracle ecurity Patching Java and WL Installed middle Tier components Tuxedo WebLogic JDK and Java Performing People oft database refresh Troubleshooting Application ervers Process cheduler servers for Reports posting and performance issues Resolved developer issues like resetting passwords and locking unlocking users Examining and clearing cache from servers like application server on monthly maintenance process Prepared and maintained the documentation of the all Non Prod and Prod Refresh Organization afalta InfoTech Pvt Ltd Nov to Aug PROJECT Multiple clients University of Texas ystems UT Papa Jones DURATION to ROLE People oft DBAENVIRONMENT People Tools HRM F CM Campus olutions Portal olutions Tuxedo WebLogic and Oracle g and c RE PON IBILITIE Implemented complete People oft life cycle from scratch to production go live activities in Executing People oft Internet Architecture PIA Demo Development upport Test and Production instances P ADMIN utility to Administer and create App server process scheduler server and webserver domains Installed middle Tier components Tuxedo WebLogic JDK and Java Performed People oft database refresh and People oft cloning activities Performing Project Migration using Application DesignerMaintaining workflow of People oft users monitoring log files and search bottleneck of servers Troubleshooting Application ervers Process cheduler servers for Reports posting and performance issues Resolved developer issues like resetting passwords and locking unlocking users Provided resolutions to client and analysed production issues Examining and clearing cache from servers like application server on monthly maintenance process etup for Integration Broker defining Gateway creating and configuring application nodes Prepared and maintained the documentation of the entire configuration Running Audit reports and reviews the Y and DDD audit for any data inconsistency Performed Data migration while performing production moves Performed server load balancing for webserver and Application tiers Hands on experience on setting up the PUM DPK images for creating change packages for Application fixes and bugs Configured Change Assistant to Download Updates and Fixes and apply to the target environments Install and configure Elastic search Performed and executed Oracle CPU quarterly security patches for nprod and prod environments Perfumed Instances verification tests for patching database refresh cloning activities Performed People Tools upgrade from release to Install and configure DPK images for extracting People oft change packages for bugs fixes and tax updates Troubleshooting for reports posting issues and IB related issues in production and nprod environments PROJECT Multiple clients Daytona tate University D C Algonquin College Canada DURATION to ROLE People oft DBAENVIRONMENT Implementation and Production upport HRM F CM Portal All Development Functional Testing Acceptance Testing and DEMO MODULE HCM F CM C PIHUB with People tools RE PON IBILITIE Created People oft Demo ystem and Production Instances Configured Application server Domains web server Batch process scheduler server Troubleshooting the various issues of Application server Web server and process cheduler domains Configured windows development clients to connect tier or tier to the database for the development and administration purposes Download Updates and Fixes and stored for Implementation Install configure Change Assistant Applying bundles and fixes Involved in Tools only upgrade from to Configured Change Assistant to Download Updates and Fixes and apply to the environments and maintain the customization for the People oft Enable tracing through PIA page and configuration manager Database pre and post refresh activities etup for Integration Broker defining Gateway creating and configuring application nodes Running Audit reports and reviews the Y and DDD audit for any data inconsistency Installed and configured verity search Technical kills Troubleshooting for reports posting issues and IB related issues in production and nprod environments People Tools People oft Applications Oracle DB g g Web Logic Tuxedo UNIX Windows NT R People oft Admin DBA Oracle DBAMulti Tasking Effective and Good Team Player Good Interaction with customers elf motivated and quick learner of new concepts and technologies Education Bachelors in Computer cience Anil Neerukonda Institute of technology and sciences Andhra University Awards Client delight Award for best performance port Award for achieving good C AT score from end users Personal details Father s Name G Ananda RayuduDate of Birth Marital tatus inglePAN Details AVQPG QPassport Details J I hereby declare that the above mentioned information is true to the best of my knowledge PLACE G Ananda Rayudu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_resume'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342376cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a47bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(df['Category'])\n",
    "df['Category'] = le.transform(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9395928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8234b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Resume',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de644f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>cleaned_resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Anubhav Kumar ingh To work in a globally comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Profile ummary years of experience in impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>People oft Database Administrator Gangareddy P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>MuraliExperience ummary I have years of experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Priyanka Ramadoss MountPleasant CoonoorThe Nil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>Workday Integration ConsultantName ri Krishna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>eeking suitable positions in Workday HCM as T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>WORKDAY HCM FCMName Kumar Role Workday Consult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>Venkateswarlu B Workday Consultant Having year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>Vinay kumar v Workday Functional ConsultantEX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                     cleaned_resume\n",
       "0          0   Anubhav Kumar ingh To work in a globally comp...\n",
       "1          0   Profile ummary years of experience in impleme...\n",
       "2          0  People oft Database Administrator Gangareddy P...\n",
       "3          0  MuraliExperience ummary I have years of experi...\n",
       "4          0  Priyanka Ramadoss MountPleasant CoonoorThe Nil...\n",
       "..       ...                                                ...\n",
       "74         3   Workday Integration ConsultantName ri Krishna...\n",
       "75         3   eeking suitable positions in Workday HCM as T...\n",
       "76         3  WORKDAY HCM FCMName Kumar Role Workday Consult...\n",
       "77         3  Venkateswarlu B Workday Consultant Having year...\n",
       "78         3   Vinay kumar v Workday Functional ConsultantEX...\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223319ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vector = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "vector.fit(df['cleaned_resume'])\n",
    "required_text = vector.transform(df['cleaned_resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba2fbdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>cleaned_resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Anubhav Kumar ingh To work in a globally comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Profile ummary years of experience in impleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>People oft Database Administrator Gangareddy P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>MuraliExperience ummary I have years of experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Priyanka Ramadoss MountPleasant CoonoorThe Nil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>Workday Integration ConsultantName ri Krishna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>eeking suitable positions in Workday HCM as T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>WORKDAY HCM FCMName Kumar Role Workday Consult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>Venkateswarlu B Workday Consultant Having year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>Vinay kumar v Workday Functional ConsultantEX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                     cleaned_resume\n",
       "0          0   Anubhav Kumar ingh To work in a globally comp...\n",
       "1          0   Profile ummary years of experience in impleme...\n",
       "2          0  People oft Database Administrator Gangareddy P...\n",
       "3          0  MuraliExperience ummary I have years of experi...\n",
       "4          0  Priyanka Ramadoss MountPleasant CoonoorThe Nil...\n",
       "..       ...                                                ...\n",
       "74         3   Workday Integration ConsultantName ri Krishna...\n",
       "75         3   eeking suitable positions in Workday HCM as T...\n",
       "76         3  WORKDAY HCM FCMName Kumar Role Workday Consult...\n",
       "77         3  Venkateswarlu B Workday Consultant Having year...\n",
       "78         3   Vinay kumar v Workday Functional ConsultantEX...\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc2caa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<79x4550 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18050 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb5c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(required_text, df['Category'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc7a8242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 4550)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f65212a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a0e0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54875085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4550)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2c7ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "clf.fit(X_train,y_train)\n",
    "ypred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7fe4700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 3, 0, 0, 2, 1, 3, 1, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc9b095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Multinomial Naive Bayes...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n",
      "============================================================\n",
      "Evaluating Logistic Regression...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.96        24\n",
      "   macro avg       0.97      0.96      0.96        24\n",
      "weighted avg       0.96      0.96      0.96        24\n",
      "\n",
      "============================================================\n",
      "Evaluating Random Forest...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n",
      "============================================================\n",
      "Evaluating Support Vector Machine...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.96        24\n",
      "   macro avg       0.97      0.96      0.96        24\n",
      "weighted avg       0.96      0.96      0.96        24\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Dictionary containing classifiers\n",
    "classifiers = {\n",
    "    \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(required_text, df['Category'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Iterate over classifiers\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    # Evaluate the classifier\n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(report)\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eeb5193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1 0 1 1 1 1 0 3 0 0 2 1 3 1 3 2]\n",
      "Actual labels: [1 0 1 1 0 1 0 3 0 0 2 1 3 1 3 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89         5\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.96      0.95      0.95        16\n",
      "weighted avg       0.95      0.94      0.94        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(required_text, df['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Train the classifier\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = logistic_regression.predict(X_test)\n",
    "\n",
    "# Print predicted labels alongside actual labels\n",
    "print(\"Predicted labels:\", predictions)\n",
    "print(\"Actual labels:\", y_test.values)\n",
    "\n",
    "# Evaluate the classifier\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, predictions)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35b4773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cd8f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Model.pkl\",\"wb\") as file:\n",
    "    pickle.dump(logistic_regression,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d2663b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vector,open('similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "683ae0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_regression,open('logistic.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb001ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
